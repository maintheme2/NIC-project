{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders.woe import WOEEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from NiaPy.task import StoppingTask, OptimizationType\n",
    "from NiaPy.algorithms.basic import GreyWolfOptimizer, FireflyAlgorithm, GeneticAlgorithm, \\\n",
    "    BatAlgorithm, ParticleSwarmOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m f1_score\n\u001B[1;32m      4\u001B[0m clf \u001B[38;5;241m=\u001B[39m XGBRFClassifier()\n\u001B[0;32m----> 5\u001B[0m clf\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train\u001B[49m, y_train)\n\u001B[1;32m      6\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[1;32m      7\u001B[0m f1_score(y_test, y_pred)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "clf = XGBRFClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9718059436118872"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def random_undersample(x, y):\n",
    "    \"\"\"\n",
    "    Undersample data by random choosing samples from majority class.\n",
    "    :param x: train data features.\n",
    "    :param y: train data labels.\n",
    "    :return: x, y after undersampling.\n",
    "    \"\"\"\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    return rus.fit_resample(x, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "X_train, y_train = random_undersample(X_train, y_train)\n",
    "X_test = X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    return DecisionTreeClassifier(random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "from NiaPy.benchmarks import Benchmark\n",
    "\n",
    "\n",
    "class ClassificationBenchmark(Benchmark):\n",
    "    \"\"\"\n",
    "    NiaPy benchmark for classification task.\n",
    "\n",
    "    :param model_fn: function which returns sklearn model.\n",
    "    :param eval_fn: function(y_test, y_pred) which evaluates predictions\n",
    "         and returns a scalar.\n",
    "    :param x_train: train data.\n",
    "    :param y_train: train labels.\n",
    "    :param x_test: test data.\n",
    "    :param y_test: test labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_fn, eval_fn, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.model_fn = model_fn\n",
    "        self.eval_fn = eval_fn\n",
    "\n",
    "        Benchmark.__init__(self, 0, 1)\n",
    "\n",
    "    def get_length(self):\n",
    "        \"\"\"\n",
    "        Get length of the vector which is being optimized.\n",
    "\n",
    "        :return: length of the vector which is being optimized.\n",
    "        \"\"\"\n",
    "        return len(self.x_train.columns)\n",
    "\n",
    "    def select_columns(self, solution_vec):\n",
    "        \"\"\"\n",
    "        Select columns based on the solution vector.\n",
    "\n",
    "        :param solution_vec: solution of the problem as a vector.\n",
    "        :return: list of column names based on the solution vector.\n",
    "        \"\"\"\n",
    "        return self.x_train.columns[solution_vec >= 0.5].tolist()\n",
    "\n",
    "    def function(self):\n",
    "        def evaluate(_, solution_vec):\n",
    "            selected_columns = self.select_columns(solution_vec)\n",
    "\n",
    "            # fix of incorrect serialization when using multi threading module\n",
    "            if len(selected_columns) == 1 and \\\n",
    "                    not isinstance(selected_columns[0], str):\n",
    "                selected_columns = selected_columns[0]\n",
    "\n",
    "            if len(selected_columns) < 1:\n",
    "                # inverted score, since the optimizer minimizes the task\n",
    "                return 1 - 0\n",
    "\n",
    "            clf = self.model_fn()\n",
    "            clf = clf.fit(self.x_train[selected_columns], self.y_train)\n",
    "\n",
    "            y_pred = clf.predict(self.x_test[selected_columns])\n",
    "            score = self.eval_fn(self.y_test, y_pred)\n",
    "\n",
    "            # inverted score, since the optimizer minimizes the task\n",
    "            return 1 - score\n",
    "\n",
    "        return evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "benchmark = ClassificationBenchmark(model_fn,\n",
    "                                    accuracy_score,\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    X_test,\n",
    "                                    y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def optimize(benchmark, algorithm, nGEN, num_runs = 5):\n",
    "    \"\"\"\n",
    "    Optimize task with provided algorithm.\n",
    "\n",
    "    :param benchmark: NiaPy.Benchmark to optimize.\n",
    "    :param algorithm: algorithm object to use for optimization task.\n",
    "    :param nGEN: number of generations.\n",
    "    :param num_runs: number of algorithm runs (defaults to 5).\n",
    "    \"\"\"\n",
    "    best_columns = None\n",
    "    best_score = 0\n",
    "\n",
    "    for i in tqdm(range(num_runs)):\n",
    "        # when using OptimizationType.MAXIMIZATION, the library will fail\n",
    "        # we use OptimizationType.MINIMIZATION instead and invert the score\n",
    "        task = StoppingTask(\n",
    "            D=benchmark.get_length(),\n",
    "            nGEN=nGEN,\n",
    "            optType=OptimizationType.MINIMIZATION,\n",
    "            benchmark=benchmark\n",
    "        )\n",
    "\n",
    "        solution_vec, score = algorithm.run(task=task)\n",
    "        # invert the score\n",
    "        score = 1 - score\n",
    "        columns = benchmark.select_columns(solution_vec)\n",
    "\n",
    "        print('--------------')\n",
    "        print(f'Run {i + 1}')\n",
    "        print('--------------')\n",
    "        print(f'Score: {score}')\n",
    "        print(f'Number of features selected: {len(columns)}\\n')\n",
    "        print('\\n')\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_columns = columns\n",
    "\n",
    "    print(f'\\nBest score of {num_runs} runs: {best_score}')\n",
    "    print(f'Number of features selected: {len(best_columns)}')\n",
    "\n",
    "    return best_columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3         4         5         6    \\\n0    -0.375099  0.797244  0.570168 -0.035788 -0.057743  6.410245  1.372399   \n1    -0.370550 -0.098583 -0.092111 -0.035788 -0.057743 -0.217004 -0.113986   \n2     1.345121 -0.098583 -0.092111 -0.035788 -0.057743 -0.217004 -0.113986   \n3     0.976858 -0.098583 -0.092111 -0.035788 -0.057743 -0.217004 -0.113986   \n4    -0.149592 -0.098583 -0.092111 -0.035788 -0.042562 -0.217004 -0.113986   \n...        ...       ...       ...       ...       ...       ...       ...   \n8219 -0.413875 -0.075213 -0.045283 -0.035788 -0.057743 -0.140388  0.031738   \n8220 -0.437556  1.420428  1.687346 -0.035788  0.731668 -0.217004  0.629206   \n8221  0.396303 -0.098583 -0.092111 -0.035788 -0.057743 -0.217004 -0.113986   \n8222 -0.149592 -0.098583 -0.092111 -0.035788 -0.042562 -0.217004 -0.113986   \n8223  0.933533 -0.059634 -0.078732 -0.035788 -0.042562 -0.217004 -0.099414   \n\n           7         8         9    ...  222       223       224       225  \\\n0    -0.045217 -0.052667  4.149713  ...  0.0 -0.554788 -0.439415 -0.484877   \n1    -0.045217 -0.052667 -0.210538  ...  0.0 -0.554788  0.000000 -0.496415   \n2    -0.045217 -0.052667 -0.210538  ...  0.0 -0.554788  0.682728 -0.496415   \n3    -0.045217 -0.052667 -0.210538  ...  0.0 -0.554788 -0.528362 -0.429678   \n4    -0.045217 -0.041771 -0.270267  ...  1.0  0.477773  0.335557  0.367303   \n...        ...       ...       ...  ...  ...       ...       ...       ...   \n8219 -0.045217 -0.052667 -0.091079  ...  0.0 -0.554788  2.340956  0.579292   \n8220  0.829217  1.385665 -0.270267  ...  1.0  1.284766  3.167634  2.015533   \n8221 -0.045217 -0.052667 -0.210538  ...  0.0 -0.554788 -0.415885 -0.599558   \n8222 -0.045217 -0.052667 -0.270267  ...  1.0 -0.028327  0.647636  0.301360   \n8223 -0.045217 -0.041771 -0.270267  ...  1.0 -0.028327  0.000000 -0.496415   \n\n           226       227       228       229       230       231  \n0    -0.358965  0.011083 -0.147243 -0.499915 -0.383702  0.226201  \n1    -0.358965  0.011083 -0.147243 -0.474585 -0.383702 -0.446561  \n2    -0.358965  0.011083 -0.147243 -0.184240 -0.383702 -0.490869  \n3    -0.358965  0.011083 -0.147243 -0.239920 -0.383702 -0.446561  \n4    -0.358965 -0.046083  0.642275 -0.474585 -0.383702  0.226201  \n...        ...       ...       ...       ...       ...       ...  \n8219 -0.358965  0.011083 -0.147243  0.119928 -0.383702  0.226201  \n8220  1.414037 -0.046083  0.059207  1.289880  1.289880  0.505240  \n8221 -0.358965 -0.046083  0.059207 -0.184240 -0.383702 -0.446561  \n8222 -0.358965  0.011083 -0.147243  1.935491 -0.383702  0.226201  \n8223  3.321785  0.011083  1.563728 -1.040978 -0.383702  0.226201  \n\n[8224 rows x 232 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>222</th>\n      <th>223</th>\n      <th>224</th>\n      <th>225</th>\n      <th>226</th>\n      <th>227</th>\n      <th>228</th>\n      <th>229</th>\n      <th>230</th>\n      <th>231</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.375099</td>\n      <td>0.797244</td>\n      <td>0.570168</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>6.410245</td>\n      <td>1.372399</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>4.149713</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>-0.439415</td>\n      <td>-0.484877</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>-0.499915</td>\n      <td>-0.383702</td>\n      <td>0.226201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.370550</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.210538</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>0.000000</td>\n      <td>-0.496415</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>-0.474585</td>\n      <td>-0.383702</td>\n      <td>-0.446561</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.345121</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.210538</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>0.682728</td>\n      <td>-0.496415</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>-0.184240</td>\n      <td>-0.383702</td>\n      <td>-0.490869</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.976858</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.210538</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>-0.528362</td>\n      <td>-0.429678</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>-0.239920</td>\n      <td>-0.383702</td>\n      <td>-0.446561</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.149592</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.042562</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.041771</td>\n      <td>-0.270267</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.477773</td>\n      <td>0.335557</td>\n      <td>0.367303</td>\n      <td>-0.358965</td>\n      <td>-0.046083</td>\n      <td>0.642275</td>\n      <td>-0.474585</td>\n      <td>-0.383702</td>\n      <td>0.226201</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8219</th>\n      <td>-0.413875</td>\n      <td>-0.075213</td>\n      <td>-0.045283</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>-0.140388</td>\n      <td>0.031738</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.091079</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>2.340956</td>\n      <td>0.579292</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>0.119928</td>\n      <td>-0.383702</td>\n      <td>0.226201</td>\n    </tr>\n    <tr>\n      <th>8220</th>\n      <td>-0.437556</td>\n      <td>1.420428</td>\n      <td>1.687346</td>\n      <td>-0.035788</td>\n      <td>0.731668</td>\n      <td>-0.217004</td>\n      <td>0.629206</td>\n      <td>0.829217</td>\n      <td>1.385665</td>\n      <td>-0.270267</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.284766</td>\n      <td>3.167634</td>\n      <td>2.015533</td>\n      <td>1.414037</td>\n      <td>-0.046083</td>\n      <td>0.059207</td>\n      <td>1.289880</td>\n      <td>1.289880</td>\n      <td>0.505240</td>\n    </tr>\n    <tr>\n      <th>8221</th>\n      <td>0.396303</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.057743</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.210538</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-0.554788</td>\n      <td>-0.415885</td>\n      <td>-0.599558</td>\n      <td>-0.358965</td>\n      <td>-0.046083</td>\n      <td>0.059207</td>\n      <td>-0.184240</td>\n      <td>-0.383702</td>\n      <td>-0.446561</td>\n    </tr>\n    <tr>\n      <th>8222</th>\n      <td>-0.149592</td>\n      <td>-0.098583</td>\n      <td>-0.092111</td>\n      <td>-0.035788</td>\n      <td>-0.042562</td>\n      <td>-0.217004</td>\n      <td>-0.113986</td>\n      <td>-0.045217</td>\n      <td>-0.052667</td>\n      <td>-0.270267</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.028327</td>\n      <td>0.647636</td>\n      <td>0.301360</td>\n      <td>-0.358965</td>\n      <td>0.011083</td>\n      <td>-0.147243</td>\n      <td>1.935491</td>\n      <td>-0.383702</td>\n      <td>0.226201</td>\n    </tr>\n    <tr>\n      <th>8223</th>\n      <td>0.933533</td>\n      <td>-0.059634</td>\n      <td>-0.078732</td>\n      <td>-0.035788</td>\n      <td>-0.042562</td>\n      <td>-0.217004</td>\n      <td>-0.099414</td>\n      <td>-0.045217</td>\n      <td>-0.041771</td>\n      <td>-0.270267</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>-0.028327</td>\n      <td>0.000000</td>\n      <td>-0.496415</td>\n      <td>3.321785</td>\n      <td>0.011083</td>\n      <td>1.563728</td>\n      <td>-1.040978</td>\n      <td>-0.383702</td>\n      <td>0.226201</td>\n    </tr>\n  </tbody>\n</table>\n<p>8224 rows × 232 columns</p>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "columns = optimize(benchmark, FireflyAlgorithm(), 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cols:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:00<00:00, 200717.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 87344.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 332110.49it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['dist1', 'dist2', 'D5', 'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m preprocess\n\u001B[0;32m----> 3\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Downloads/preprocessing.py:81\u001B[0m, in \u001B[0;36mpreprocess\u001B[0;34m()\u001B[0m\n\u001B[1;32m     79\u001B[0m num_featurs \u001B[38;5;241m=\u001B[39m get_num_features(train, cat_features)\n\u001B[1;32m     80\u001B[0m train, to_drop \u001B[38;5;241m=\u001B[39m drop_features(train, cat_features, num_featurs)\n\u001B[0;32m---> 81\u001B[0m \u001B[43mfill_empty_cells\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_featurs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     83\u001B[0m data \u001B[38;5;241m=\u001B[39m train\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransactionID\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransactionDT\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     84\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124misFraud\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[0;32m~/Downloads/preprocessing.py:55\u001B[0m, in \u001B[0;36mfill_empty_cells\u001B[0;34m(train, cat_features, num_features)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfill_empty_cells\u001B[39m(train, cat_features, num_features):\n\u001B[0;32m---> 55\u001B[0m     median_values \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnum_features\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmedian()\n\u001B[1;32m     57\u001B[0m     train[num_features] \u001B[38;5;241m=\u001B[39m train[num_features]\u001B[38;5;241m.\u001B[39mfillna(median_values)\n\u001B[1;32m     58\u001B[0m     train[cat_features] \u001B[38;5;241m=\u001B[39m train[cat_features]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnan\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmissing\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3810\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3809\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3810\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3812\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6111\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6108\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6109\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6111\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6113\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6115\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6174\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6171\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6173\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m-> 6174\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['dist1', 'dist2', 'D5', 'D6', 'D7', 'D8', 'D9', 'D12', 'D13', 'D14', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11'] not in index\""
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
